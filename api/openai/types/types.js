/**
 * @typedef {Object} ChatCompletion
 * @property {string} id - A unique identifier for the chat completion
 * @property {ChatCompletionChoices[]} choices - A list of chat completion choices. Can be more than one if n is greater than 1.
 * @property {number} created - The Unix timestamp (in seconds) of when the chat completion was created
 * @property {string} model - The model used for the chat completion
 * @property {?string} system_fingerprint
 * - This fingerprint represents the backend configuration that the model runs with.  
 * - Can be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.
 * @property {OpenAIUsage} usage - Usage statistics for the completion request
 */

/**
 * @typedef {Object} ChatCompletionChoices
 * @property {number} index - The index of the choice in the list of choices
 * @property {string} finish_reason
 * - The reason the model stopped generating tokens.  
 * - This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `tool_calls` if the model called a tool.
 * @property {ChatCompletionMessage} message - A chat completion message generated by the model
 * @property {?LogProbability} logprobs - Log probability information for the choice
 */

/**
 * @typedef {Object} ChatCompletionMessage
 * @property {?string} content - The contents of the message
 * @property {string} role - The role of the author of this message
 * @property {ToolCalls[]} tool_calls - The tool calls generated by the model, such as function calls
 */

/**
 * @typedef {Object} ToolCalls
 * @property {string} id - The ID of the tool call
 * @property {string} type - The type of the tool. Currently, only function is supported.
 * @property {ToolCallsFunction} function - The function that the model called
 */

/**
 * @typedef {Object} ToolCallsFunction
 * @property {string} name - The name of the function to call
 * @property {string} arguments
 * - The arguments to call the function with, as generated by the model in JSON format.  
 * - Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema.  
 * - Validate the arguments in your code before calling your function.
 */

/**
 * @typedef {Object} LogProbability
 * @property {?LogProbabilityInformation[]} content - A list of message content tokens with log probability information
 */

/**
 * @typedef {Object} LogProbabilityInformation
 * @property {string} token - The token
 * @property {number} logprob - The log probability of this token
 * @property {?Array<number>} bytes - A list of integers representing the UTF-8 bytes representation of the token
 * @property {TopLogProbability[]} top_logprobs - List of the most likely tokens and their log probability, at this token position
 */

/**
 * @typedef {Object} TopLogProbability
 * @property {string} token - The token
 * @property {number} logprob - The log probability of this token
 * @property {?Array<number>} bytes - A list of integers representing the UTF-8 bytes representation of the token
 */

/**
 * @typedef {Object} OpenAIUsage
 * @property {number} prompt_tokens - Number of tokens in the prompt
 * @property {number} completion_tokens - Number of tokens in the generated completion
 * @property {number} total_tokens - Total number of tokens used in the request (prompt + completion)
 */

/**
 * @typedef {Object} OpenAIImageResponse
 * @property {number} created
 * @property {OpenAIImage[]} data
 */

/**
 * @typedef {Object} OpenAIImage
 * @property {string} [b64_json] - The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.
 * @property {string} [url] - The URL of the generated image, if `response_format` is `url` (default).
 * @property {string} [revised_prompt] - The prompt that was used to generate the image, if there was any revision to the prompt
 */