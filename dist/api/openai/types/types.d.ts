export type ChatCompletion = {
    /**
     * - A unique identifier for the chat completion
     */
    id: string;
    /**
     * - A list of chat completion choices. Can be more than one if n is greater than 1.
     */
    choices: ChatCompletionChoice[];
    /**
     * - The Unix timestamp (in seconds) of when the chat completion was created
     */
    created: number;
    /**
     * - The model used for the chat completion
     */
    model: string;
    /**
     * - This fingerprint represents the backend configuration that the model runs with.
     * - Can be used in conjunction with the seed request parameter to understand when backend changes have been made that might impact determinism.
     */
    system_fingerprint: string | null;
    /**
     * - Usage statistics for the completion request
     */
    usage: OpenAIUsage;
};
export type ChatCompletionChoice = {
    /**
     * - The index of the choice in the list of choices
     */
    index: number;
    /**
     * - The reason the model stopped generating tokens.
     * - This will be `stop` if the model hit a natural stop point or a provided stop sequence, `length` if the maximum number of tokens specified in the request was reached, `content_filter` if content was omitted due to a flag from our content filters, or `tool_calls` if the model called a tool.
     */
    finish_reason: string;
    /**
     * - A chat completion message generated by the model
     */
    message: ChatCompletionMessage;
    /**
     * - Log probability information for the choice
     */
    logprobs: LogProbability | null;
};
export type ChatCompletionMessage = {
    /**
     * - The contents of the message
     */
    content: string | null;
    /**
     * - The role of the author of this message
     */
    role: string;
    /**
     * - The tool calls generated by the model, such as function calls
     */
    tool_calls: ToolCalls[];
};
export type ToolCalls = {
    /**
     * - The ID of the tool call
     */
    id: string;
    /**
     * - The type of the tool. Currently, only function is supported.
     */
    type: string;
    /**
     * - The function that the model called
     */
    function: ToolCallsFunction;
};
export type ToolCallsFunction = {
    /**
     * - The name of the function to call
     */
    name: string;
    /**
     * - The arguments to call the function with, as generated by the model in JSON format.
     * - Note that the model does not always generate valid JSON, and may hallucinate parameters not defined by your function schema.
     * - Validate the arguments in your code before calling your function.
     */
    arguments: string;
};
export type LogProbability = {
    /**
     * - A list of message content tokens with log probability information
     */
    content: LogProbabilityInformation[] | null;
};
export type LogProbabilityInformation = {
    /**
     * - The token
     */
    token: string;
    /**
     * - The log probability of this token
     */
    logprob: number;
    /**
     * - A list of integers representing the UTF-8 bytes representation of the token
     */
    bytes: Array<number> | null;
    /**
     * - List of the most likely tokens and their log probability, at this token position
     */
    top_logprobs: TopLogProbability[];
};
export type TopLogProbability = {
    /**
     * - The token
     */
    token: string;
    /**
     * - The log probability of this token
     */
    logprob: number;
    /**
     * - A list of integers representing the UTF-8 bytes representation of the token
     */
    bytes: Array<number> | null;
};
export type OpenAIUsage = {
    /**
     * - Number of tokens in the prompt
     */
    prompt_tokens: number;
    /**
     * - Number of tokens in the generated completion
     */
    completion_tokens: number;
    /**
     * - Total number of tokens used in the request (prompt + completion)
     */
    total_tokens: number;
};
export type OpenAIImageResponse = {
    created: number;
    data: OpenAIImage[];
};
export type OpenAIImage = {
    /**
     * - The base64-encoded JSON of the generated image, if `response_format` is `b64_json`.
     */
    b64_json?: string | undefined;
    /**
     * - The URL of the generated image, if `response_format` is `url` (default).
     */
    url?: string | undefined;
    /**
     * - The prompt that was used to generate the image, if there was any revision to the prompt
     */
    revised_prompt?: string | undefined;
};

export type OpenAIEmbedding = {
    index: number;
    embedding: number[];
    object: string;
};

export type OpenAIEmbeddingResponse = {
    object: string;
    data: OpenAIEmbedding[];
    model: string;
    usage: OpenAIUsage
}
//# sourceMappingURL=types.d.ts.map